{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: ['Number of Bends']\n",
      "Data Summary:\n",
      "       Number of Bends\n",
      "count        50.000000\n",
      "mean          5.100000\n",
      "std           1.897904\n",
      "min           2.000000\n",
      "25%           4.000000\n",
      "50%           5.000000\n",
      "75%           7.000000\n",
      "max           8.000000\n",
      "\n",
      "Decision Tree Accuracy: 1.0\n",
      "\n",
      "Comparison of Predicted vs Original Values:\n",
      "   Original Predicted\n",
      "13     High      High\n",
      "39   Medium    Medium\n",
      "30     High      High\n",
      "45      Low       Low\n",
      "17      Low       Low\n",
      "48     High      High\n",
      "26      Low       Low\n",
      "25   Medium    Medium\n",
      "32   Medium    Medium\n",
      "19   Medium    Medium\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('road_transport_records.csv')\n",
    "\n",
    "# Feature selection\n",
    "X = df.drop(['Road_ID', 'AccidentRisk'], axis=1)\n",
    "y = df['AccidentRisk']\n",
    "mi_scores = mutual_info_classif(X, y)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "selected_features = mi_scores[mi_scores > mi_scores.median()].index.tolist()\n",
    "\n",
    "# Discretization\n",
    "kbd = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "X_binned = pd.DataFrame(kbd.fit_transform(X[selected_features]), columns=selected_features)\n",
    "\n",
    "# ID3 Algorithm Implementation\n",
    "class Node:\n",
    "    def __init__(self, attribute=None, label=None, branches=None):\n",
    "        self.attribute = attribute\n",
    "        self.label = label\n",
    "        self.branches = branches or {}\n",
    "\n",
    "def entropy(y):\n",
    "    counter = Counter(y)\n",
    "    probs = [count / len(y) for count in counter.values()]\n",
    "    return -sum(p * np.log2(p) for p in probs if p > 0)\n",
    "\n",
    "def information_gain(X, y, attribute):\n",
    "    total_entropy = entropy(y)\n",
    "    weighted_entropy = 0\n",
    "    for value in X[attribute].unique():\n",
    "        subset = y[X[attribute] == value]\n",
    "        weighted_entropy += len(subset) / len(y) * entropy(subset)\n",
    "    return total_entropy - weighted_entropy\n",
    "\n",
    "def id3(X, y, attributes, max_depth=3, min_samples=5):\n",
    "    if len(set(y)) == 1:\n",
    "        return Node(label=y.iloc[0])\n",
    "    \n",
    "    if not attributes or len(y) < min_samples or max_depth == 0:\n",
    "        return Node(label=Counter(y).most_common(1)[0][0])\n",
    "    \n",
    "    best_attribute = max(attributes, key=lambda a: information_gain(X, y, a))\n",
    "    node = Node(attribute=best_attribute)\n",
    "    \n",
    "    for value in X[best_attribute].unique():\n",
    "        subset_X = X[X[best_attribute] == value].drop(columns=[best_attribute])\n",
    "        subset_y = y[X[best_attribute] == value]\n",
    "        new_attributes = [a for a in attributes if a != best_attribute]\n",
    "        node.branches[value] = id3(subset_X, subset_y, new_attributes, max_depth-1, min_samples)\n",
    "    \n",
    "    return node\n",
    "\n",
    "def predict(node, instance):\n",
    "    if node.label is not None:\n",
    "        return node.label\n",
    "    value = instance[node.attribute]\n",
    "    if value not in node.branches:\n",
    "        return max(Counter(df['AccidentRisk']).items(), key=lambda x: x[1])[0]\n",
    "    return predict(node.branches[value], instance)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_binned, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "attributes = list(X_train.columns)\n",
    "root = id3(X_train, y_train, attributes, max_depth=3)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = [predict(root, row) for _, row in X_test.iterrows()]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print summary and results\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Data Summary:\")\n",
    "print(df[selected_features + ['AccidentRisk']].describe())\n",
    "print(\"\\nDecision Tree Accuracy:\", accuracy)\n",
    "print(\"\\nComparison of Predicted vs Original Values:\")\n",
    "comparison = pd.DataFrame({'Original': y_test, 'Predicted': y_pred})\n",
    "print(comparison.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('road_transport_records.csv')\n",
    "\n",
    "# Prepare the data\n",
    "X = df.drop(['Road_ID', 'AccidentRisk'], axis=1)\n",
    "y = df['AccidentRisk']\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model using sklearn's DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Visualize the decision tree using matplotlib\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, \n",
    "          feature_names=X.columns,  \n",
    "          class_names=le.classes_,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          fontsize=10)\n",
    "plt.title(\"Decision Tree for Accident Risk\", fontsize=20)\n",
    "plt.savefig(\"decision_tree.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
